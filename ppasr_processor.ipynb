{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 01 安装需要的依赖和部署预训练模型"
      ],
      "metadata": {
        "id": "EblwyDLicmnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install paddlepaddle-gpu==2.4.1.post112 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "!python -m pip install ppasr\n",
        "!pip install pypinyin\n",
        "!python -m pip install paddlespeech-ctcdecoders\n",
        "!git clone https://github.com/AlexandaJerry/PPASR.git\n",
        "%cd /content/PPASR\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "Sf0YXv8Vcnu4",
        "outputId": "9e919691-c1ed-4fcd-b0da-bdc768791ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
            "Collecting paddlepaddle-gpu==2.4.1.post112\n",
            "  Downloading https://paddle-wheel.bj.bcebos.com/release/2.4/linux/linux-gpu-cuda11.2-cudnn8-mkl-gcc8.2-avx/paddlepaddle_gpu-2.4.1.post112-cp38-cp38-linux_x86_64.whl (547.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 547.9 MB 14 kB/s \n",
            "\u001b[?25hCollecting paddle-bfloat==0.1.7\n",
            "  Downloading paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (2.23.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (3.3.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (0.8.1)\n",
            "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (3.19.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (7.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from paddlepaddle-gpu==2.4.1.post112) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.1.post112) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.1.post112) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.1.post112) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.1.post112) (3.0.4)\n",
            "Installing collected packages: paddle-bfloat, paddlepaddle-gpu\n",
            "Successfully installed paddle-bfloat-0.1.7 paddlepaddle-gpu-2.4.1.post112\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ppasr\n",
            "  Downloading ppasr-2.1.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 766 kB/s \n",
            "\u001b[?25hCollecting ffmpeg-python>=0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting visualdl>=2.1.1\n",
            "  Downloading visualdl-2.4.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 67.5 MB/s \n",
            "\u001b[?25hCollecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting cn2an>=0.5.17\n",
            "  Downloading cn2an-0.5.19-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from ppasr) (0.4.2)\n",
            "Collecting requests>=2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.8/dist-packages (from ppasr) (1.21.6)\n",
            "Collecting paddleaudio~=1.0.1\n",
            "  Downloading paddleaudio-1.0.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 76.6 MB/s \n",
            "\u001b[?25hCollecting zhconv>=1.4.2\n",
            "  Downloading zhconv-1.4.3.tar.gz (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from ppasr) (1.0.2)\n",
            "Collecting onnxruntime>=1.11.1\n",
            "  Downloading onnxruntime-1.13.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 54.4 MB/s \n",
            "\u001b[?25hCollecting pydub~=0.25.1\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: SoundFile>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from ppasr) (0.11.0)\n",
            "Collecting ijson~=3.1.4\n",
            "  Downloading ijson-3.1.4-cp38-cp38-manylinux2010_x86_64.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 74.4 MB/s \n",
            "\u001b[?25hCollecting flask~=2.1.2\n",
            "  Downloading Flask-2.1.3-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting typeguard>=2.13.3\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from ppasr) (4.64.1)\n",
            "Collecting pyyaml~=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[K     |████████████████████████████████| 662 kB 68.0 MB/s \n",
            "\u001b[?25hCollecting websockets~=10.3\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 79.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from ppasr) (1.7.3)\n",
            "Collecting flask-cors~=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from python-Levenshtein==0.12.2->ppasr) (57.4.0)\n",
            "Collecting proces>=0.1.3\n",
            "  Downloading proces-0.1.3-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python>=0.2.0->ppasr) (0.16.0)\n",
            "Collecting Werkzeug>=2.0\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 55.9 MB/s \n",
            "\u001b[?25hCollecting Jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 70.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask~=2.1.2->ppasr) (5.1.0)\n",
            "Collecting click>=8.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.8/dist-packages (from flask-cors~=3.0.10->ppasr) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask~=2.1.2->ppasr) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask~=2.1.2->ppasr) (2.0.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.11.1->ppasr) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.11.1->ppasr) (21.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.11.1->ppasr) (1.7.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.11.1->ppasr) (1.12)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pathos==0.2.8\n",
            "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.7 MB/s \n",
            "\u001b[?25hCollecting pox>=0.3.0\n",
            "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
            "Collecting ppft>=1.6.6.4\n",
            "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting multiprocess>=0.70.12\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 79.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.8/dist-packages (from pathos==0.2.8->paddleaudio~=1.0.1->ppasr) (0.3.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.1->ppasr) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.1->ppasr) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.1->ppasr) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.1->ppasr) (2.1.1)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.8/dist-packages (from resampy>=0.2.2->ppasr) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->resampy>=0.2.2->ppasr) (0.39.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ppasr) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ppasr) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from SoundFile>=0.11.0->ppasr) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->SoundFile>=0.11.0->ppasr) (2.21)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from visualdl>=2.1.1->ppasr) (7.1.2)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce_python_sdk-0.8.74-py3-none-any.whl (204 kB)\n",
            "\u001b[K     |████████████████████████████████| 204 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from visualdl>=2.1.1->ppasr) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from visualdl>=2.1.1->ppasr) (3.2.2)\n",
            "Collecting Flask-Babel>=1.0.0\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->ppasr) (2022.6)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.8/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->ppasr) (2.11.0)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.1 MB/s \n",
            "\u001b[?25hCollecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->visualdl>=2.1.1->ppasr) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->visualdl>=2.1.1->ppasr) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->visualdl>=2.1.1->ppasr) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->visualdl>=2.1.1->ppasr) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.11.1->ppasr) (1.2.1)\n",
            "Building wheels for collected packages: python-Levenshtein, termcolor, zhconv\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp38-cp38-linux_x86_64.whl size=149832 sha256=c581e576554b5a3ff1a0c34494784a9823e8b9b32cb8c0f1f5bea4908bbaebc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/0c/76/042b46eb0df65c3ccd0338f791210c55ab79d209bcc269e2c7\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=8d89e3414d8fb4befe05623c30e9f639cdf62fed24281f2e5a89540f49be5295\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zhconv: filename=zhconv-1.4.3-py2.py3-none-any.whl size=208852 sha256=3c48ad395ec0e05ce9692add77793564be8955df0f0da279909472f749a828c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/11/df/c14a55367e9dc3cf3d605f1335d484797fc01c9d61de740bb3\n",
            "Successfully built python-Levenshtein termcolor zhconv\n",
            "Installing collected packages: MarkupSafe, Werkzeug, Jinja2, itsdangerous, click, pycryptodome, ppft, pox, multiprocess, humanfriendly, flask, requests, proces, pathos, Flask-Babel, colorlog, coloredlogs, bce-python-sdk, zhconv, websockets, visualdl, typeguard, termcolor, pyyaml, python-Levenshtein, pydub, paddleaudio, onnxruntime, ijson, flask-cors, ffmpeg-python, cn2an, ppasr\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.1\n",
            "    Uninstalling termcolor-2.1.1:\n",
            "      Successfully uninstalled termcolor-2.1.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-2.0.0 Jinja2-3.1.2 MarkupSafe-2.1.1 Werkzeug-2.2.2 bce-python-sdk-0.8.74 click-8.1.3 cn2an-0.5.19 coloredlogs-15.0.1 colorlog-6.7.0 ffmpeg-python-0.2.0 flask-2.1.3 flask-cors-3.0.10 humanfriendly-10.0 ijson-3.1.4 itsdangerous-2.1.2 multiprocess-0.70.14 onnxruntime-1.13.1 paddleaudio-1.0.2 pathos-0.2.8 pox-0.3.2 ppasr-2.1.2 ppft-1.7.6.6 proces-0.1.3 pycryptodome-3.16.0 pydub-0.25.1 python-Levenshtein-0.12.2 pyyaml-5.4.1 requests-2.28.1 termcolor-1.1.0 typeguard-2.13.3 visualdl-2.4.1 websockets-10.4 zhconv-1.4.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.47.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 33.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.47.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlespeech-ctcdecoders\n",
            "  Downloading paddlespeech_ctcdecoders-0.2.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.8 MB 22.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: paddlespeech-ctcdecoders\n",
            "Successfully installed paddlespeech-ctcdecoders-0.2.1\n",
            "Cloning into 'PPASR'...\n",
            "remote: Enumerating objects: 2201, done.\u001b[K\n",
            "remote: Counting objects: 100% (399/399), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 2201 (delta 299), reused 355 (delta 279), pack-reused 1802\u001b[K\n",
            "Receiving objects: 100% (2201/2201), 17.99 MiB | 9.21 MiB/s, done.\n",
            "Resolving deltas: 100% (1590/1590), done.\n",
            "/content/PPASR\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ppasr.egg-info\n",
            "writing ppasr.egg-info/PKG-INFO\n",
            "writing dependency_links to ppasr.egg-info/dependency_links.txt\n",
            "writing requirements to ppasr.egg-info/requires.txt\n",
            "writing top-level names to ppasr.egg-info/top_level.txt\n",
            "writing manifest file 'ppasr.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'ppasr.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ppasr\n",
            "copying ppasr/trainer.py -> build/lib/ppasr\n",
            "copying ppasr/predict.py -> build/lib/ppasr\n",
            "copying ppasr/__init__.py -> build/lib/ppasr\n",
            "creating build/lib/ppasr/infer_utils\n",
            "copying ppasr/infer_utils/vad_predictor.py -> build/lib/ppasr/infer_utils\n",
            "copying ppasr/infer_utils/inference_predictor.py -> build/lib/ppasr/infer_utils\n",
            "copying ppasr/infer_utils/pun_predictor.py -> build/lib/ppasr/infer_utils\n",
            "copying ppasr/infer_utils/__init__.py -> build/lib/ppasr/infer_utils\n",
            "creating build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/binary.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/audio.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/normalizer.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/reader.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/utils.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/sampler.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/collate_fn.py -> build/lib/ppasr/data_utils\n",
            "copying ppasr/data_utils/__init__.py -> build/lib/ppasr/data_utils\n",
            "creating build/lib/ppasr/model_utils\n",
            "copying ppasr/model_utils/__init__.py -> build/lib/ppasr/model_utils\n",
            "creating build/lib/ppasr/decoders\n",
            "copying ppasr/decoders/beam_search_decoder.py -> build/lib/ppasr/decoders\n",
            "copying ppasr/decoders/swig_wrapper.py -> build/lib/ppasr/decoders\n",
            "copying ppasr/decoders/ctc_greedy_decoder.py -> build/lib/ppasr/decoders\n",
            "copying ppasr/decoders/__init__.py -> build/lib/ppasr/decoders\n",
            "creating build/lib/ppasr/utils\n",
            "copying ppasr/utils/model_summary.py -> build/lib/ppasr/utils\n",
            "copying ppasr/utils/utils.py -> build/lib/ppasr/utils\n",
            "copying ppasr/utils/scheduler.py -> build/lib/ppasr/utils\n",
            "copying ppasr/utils/logger.py -> build/lib/ppasr/utils\n",
            "copying ppasr/utils/__init__.py -> build/lib/ppasr/utils\n",
            "copying ppasr/utils/metrics.py -> build/lib/ppasr/utils\n",
            "creating build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/spec_augment.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/volume_perturb.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/resample.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/noise_perturb.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/spec_sub.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/base.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/__init__.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/augmentation.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/speed_perturb.py -> build/lib/ppasr/data_utils/augmentor\n",
            "copying ppasr/data_utils/augmentor/shift_perturb.py -> build/lib/ppasr/data_utils/augmentor\n",
            "creating build/lib/ppasr/data_utils/featurizer\n",
            "copying ppasr/data_utils/featurizer/text_featurizer.py -> build/lib/ppasr/data_utils/featurizer\n",
            "copying ppasr/data_utils/featurizer/audio_featurizer.py -> build/lib/ppasr/data_utils/featurizer\n",
            "copying ppasr/data_utils/featurizer/__init__.py -> build/lib/ppasr/data_utils/featurizer\n",
            "creating build/lib/ppasr/model_utils/loss\n",
            "copying ppasr/model_utils/loss/label_smoothing_loss.py -> build/lib/ppasr/model_utils/loss\n",
            "copying ppasr/model_utils/loss/ctc.py -> build/lib/ppasr/model_utils/loss\n",
            "copying ppasr/model_utils/loss/__init__.py -> build/lib/ppasr/model_utils/loss\n",
            "creating build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/convolution.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/embedding.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/attention.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/model.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/encoder.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/positionwise.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/__init__.py -> build/lib/ppasr/model_utils/conformer\n",
            "copying ppasr/model_utils/conformer/subsampling.py -> build/lib/ppasr/model_utils/conformer\n",
            "creating build/lib/ppasr/model_utils/transformer\n",
            "copying ppasr/model_utils/transformer/decoder.py -> build/lib/ppasr/model_utils/transformer\n",
            "copying ppasr/model_utils/transformer/__init__.py -> build/lib/ppasr/model_utils/transformer\n",
            "creating build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/convolution.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/attention.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/model.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/encoder.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/conv2d.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/positionwise.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/__init__.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "copying ppasr/model_utils/squeezeformer/subsampling.py -> build/lib/ppasr/model_utils/squeezeformer\n",
            "creating build/lib/ppasr/model_utils/deepspeech2\n",
            "copying ppasr/model_utils/deepspeech2/model.py -> build/lib/ppasr/model_utils/deepspeech2\n",
            "copying ppasr/model_utils/deepspeech2/encoder.py -> build/lib/ppasr/model_utils/deepspeech2\n",
            "copying ppasr/model_utils/deepspeech2/conv.py -> build/lib/ppasr/model_utils/deepspeech2\n",
            "copying ppasr/model_utils/deepspeech2/__init__.py -> build/lib/ppasr/model_utils/deepspeech2\n",
            "creating build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/model_utils/utils/mask.py -> build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/model_utils/utils/cmvn.py -> build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/model_utils/utils/common.py -> build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/model_utils/utils/base.py -> build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/model_utils/utils/__init__.py -> build/lib/ppasr/model_utils/utils\n",
            "copying ppasr/infer_utils/silero_vad.onnx -> build/lib/ppasr/infer_utils\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ppasr\n",
            "copying build/lib/ppasr/trainer.py -> build/bdist.linux-x86_64/egg/ppasr\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "copying build/lib/ppasr/infer_utils/silero_vad.onnx -> build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "copying build/lib/ppasr/infer_utils/vad_predictor.py -> build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "copying build/lib/ppasr/infer_utils/inference_predictor.py -> build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "copying build/lib/ppasr/infer_utils/pun_predictor.py -> build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "copying build/lib/ppasr/infer_utils/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/infer_utils\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/binary.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/spec_augment.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/volume_perturb.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/resample.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/noise_perturb.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/spec_sub.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/base.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/augmentation.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/speed_perturb.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/augmentor/shift_perturb.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor\n",
            "copying build/lib/ppasr/data_utils/audio.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/normalizer.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/reader.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer\n",
            "copying build/lib/ppasr/data_utils/featurizer/text_featurizer.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer\n",
            "copying build/lib/ppasr/data_utils/featurizer/audio_featurizer.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer\n",
            "copying build/lib/ppasr/data_utils/featurizer/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer\n",
            "copying build/lib/ppasr/data_utils/utils.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/sampler.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/collate_fn.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/data_utils/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/data_utils\n",
            "copying build/lib/ppasr/predict.py -> build/bdist.linux-x86_64/egg/ppasr\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/loss\n",
            "copying build/lib/ppasr/model_utils/loss/label_smoothing_loss.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/loss\n",
            "copying build/lib/ppasr/model_utils/loss/ctc.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/loss\n",
            "copying build/lib/ppasr/model_utils/loss/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/loss\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/convolution.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/embedding.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/attention.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/model.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/encoder.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/positionwise.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "copying build/lib/ppasr/model_utils/conformer/subsampling.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/transformer\n",
            "copying build/lib/ppasr/model_utils/transformer/decoder.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/transformer\n",
            "copying build/lib/ppasr/model_utils/transformer/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/transformer\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/convolution.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/attention.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/model.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/encoder.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/conv2d.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/positionwise.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "copying build/lib/ppasr/model_utils/squeezeformer/subsampling.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2\n",
            "copying build/lib/ppasr/model_utils/deepspeech2/model.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2\n",
            "copying build/lib/ppasr/model_utils/deepspeech2/encoder.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2\n",
            "copying build/lib/ppasr/model_utils/deepspeech2/conv.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2\n",
            "copying build/lib/ppasr/model_utils/deepspeech2/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/utils/mask.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/utils/cmvn.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/utils/common.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/utils/base.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/utils/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils/utils\n",
            "copying build/lib/ppasr/model_utils/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/model_utils\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/decoders\n",
            "copying build/lib/ppasr/decoders/beam_search_decoder.py -> build/bdist.linux-x86_64/egg/ppasr/decoders\n",
            "copying build/lib/ppasr/decoders/swig_wrapper.py -> build/bdist.linux-x86_64/egg/ppasr/decoders\n",
            "copying build/lib/ppasr/decoders/ctc_greedy_decoder.py -> build/bdist.linux-x86_64/egg/ppasr/decoders\n",
            "copying build/lib/ppasr/decoders/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/decoders\n",
            "creating build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/model_summary.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/utils.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/scheduler.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/logger.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/__init__.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/utils/metrics.py -> build/bdist.linux-x86_64/egg/ppasr/utils\n",
            "copying build/lib/ppasr/__init__.py -> build/bdist.linux-x86_64/egg/ppasr\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/trainer.py to trainer.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/infer_utils/vad_predictor.py to vad_predictor.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/infer_utils/inference_predictor.py to inference_predictor.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/infer_utils/pun_predictor.py to pun_predictor.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/infer_utils/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/binary.py to binary.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/spec_augment.py to spec_augment.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/volume_perturb.py to volume_perturb.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/resample.py to resample.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/noise_perturb.py to noise_perturb.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/spec_sub.py to spec_sub.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/base.py to base.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/augmentation.py to augmentation.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/speed_perturb.py to speed_perturb.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/augmentor/shift_perturb.py to shift_perturb.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/audio.py to audio.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/normalizer.py to normalizer.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/reader.py to reader.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer/text_featurizer.py to text_featurizer.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer/audio_featurizer.py to audio_featurizer.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/featurizer/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/utils.py to utils.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/sampler.py to sampler.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/collate_fn.py to collate_fn.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/data_utils/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/predict.py to predict.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/loss/label_smoothing_loss.py to label_smoothing_loss.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/loss/ctc.py to ctc.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/loss/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/convolution.py to convolution.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/embedding.py to embedding.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/attention.py to attention.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/model.py to model.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/encoder.py to encoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/positionwise.py to positionwise.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/conformer/subsampling.py to subsampling.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/transformer/decoder.py to decoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/transformer/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/convolution.py to convolution.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/attention.py to attention.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/model.py to model.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/encoder.py to encoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/conv2d.py to conv2d.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/positionwise.py to positionwise.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/squeezeformer/subsampling.py to subsampling.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2/model.py to model.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2/encoder.py to encoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2/conv.py to conv.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/deepspeech2/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/utils/mask.py to mask.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/utils/cmvn.py to cmvn.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/utils/common.py to common.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/utils/base.py to base.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/utils/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/model_utils/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/decoders/beam_search_decoder.py to beam_search_decoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/decoders/swig_wrapper.py to swig_wrapper.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/decoders/ctc_greedy_decoder.py to ctc_greedy_decoder.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/decoders/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/model_summary.py to model_summary.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/utils.py to utils.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/scheduler.py to scheduler.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/logger.py to logger.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/utils/metrics.py to metrics.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ppasr/__init__.py to __init__.cpython-38.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ppasr.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ppasr.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ppasr.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ppasr.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ppasr.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "ppasr.infer_utils.__pycache__.vad_predictor.cpython-38: module references __file__\n",
            "creating dist\n",
            "creating 'dist/ppasr-2.1.2-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ppasr-2.1.2-py3.8.egg\n",
            "creating /usr/local/lib/python3.8/dist-packages/ppasr-2.1.2-py3.8.egg\n",
            "Extracting ppasr-2.1.2-py3.8.egg to /usr/local/lib/python3.8/dist-packages\n",
            "Adding ppasr 2.1.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/ppasr-2.1.2-py3.8.egg\n",
            "Processing dependencies for ppasr==2.1.2\n",
            "Searching for onnxruntime==1.13.1\n",
            "Best match: onnxruntime 1.13.1\n",
            "Adding onnxruntime 1.13.1 to easy-install.pth file\n",
            "Installing onnxruntime_test script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cn2an==0.5.19\n",
            "Best match: cn2an 0.5.19\n",
            "Adding cn2an 0.5.19 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for typeguard==2.13.3\n",
            "Best match: typeguard 2.13.3\n",
            "Adding typeguard 2.13.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for ffmpeg-python==0.2.0\n",
            "Best match: ffmpeg-python 0.2.0\n",
            "Adding ffmpeg-python 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for websockets==10.4\n",
            "Best match: websockets 10.4\n",
            "Adding websockets 10.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for requests==2.28.1\n",
            "Best match: requests 2.28.1\n",
            "Adding requests 2.28.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for paddleaudio==1.0.2\n",
            "Best match: paddleaudio 1.0.2\n",
            "Adding paddleaudio 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Flask-Cors==3.0.10\n",
            "Best match: Flask-Cors 3.0.10\n",
            "Adding Flask-Cors 3.0.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Flask==2.1.3\n",
            "Best match: Flask 2.1.3\n",
            "Adding Flask 2.1.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyYAML==5.4.1\n",
            "Best match: PyYAML 5.4.1\n",
            "Adding PyYAML 5.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pydub==0.25.1\n",
            "Best match: pydub 0.25.1\n",
            "Adding pydub 0.25.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for ijson==3.1.4\n",
            "Best match: ijson 3.1.4\n",
            "Adding ijson 3.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zhconv==1.4.3\n",
            "Best match: zhconv 1.4.3\n",
            "Adding zhconv 1.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for resampy==0.4.2\n",
            "Best match: resampy 0.4.2\n",
            "Adding resampy 0.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for soundfile==0.11.0\n",
            "Best match: soundfile 0.11.0\n",
            "Adding soundfile 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for visualdl==2.4.1\n",
            "Best match: visualdl 2.4.1\n",
            "Adding visualdl 2.4.1 to easy-install.pth file\n",
            "Installing visualdl script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for python-Levenshtein==0.12.2\n",
            "Best match: python-Levenshtein 0.12.2\n",
            "Adding python-Levenshtein 0.12.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for coloredlogs==15.0.1\n",
            "Best match: coloredlogs 15.0.1\n",
            "Adding coloredlogs 15.0.1 to easy-install.pth file\n",
            "Installing coloredlogs script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for flatbuffers==1.12\n",
            "Best match: flatbuffers 1.12\n",
            "Adding flatbuffers 1.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for protobuf==3.19.6\n",
            "Best match: protobuf 3.19.6\n",
            "Adding protobuf 3.19.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for sympy==1.7.1\n",
            "Best match: sympy 1.7.1\n",
            "Adding sympy 1.7.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for proces==0.1.3\n",
            "Best match: proces 0.1.3\n",
            "Adding proces 0.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for charset-normalizer==2.1.1\n",
            "Best match: charset-normalizer 2.1.1\n",
            "Adding charset-normalizer 2.1.1 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for certifi==2022.12.7\n",
            "Best match: certifi 2022.12.7\n",
            "Adding certifi 2022.12.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pathos==0.2.8\n",
            "Best match: pathos 0.2.8\n",
            "Adding pathos 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for colorlog==6.7.0\n",
            "Best match: colorlog 6.7.0\n",
            "Adding colorlog 6.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for itsdangerous==2.1.2\n",
            "Best match: itsdangerous 2.1.2\n",
            "Adding itsdangerous 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==2.2.2\n",
            "Best match: Werkzeug 2.2.2\n",
            "Adding Werkzeug 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for click==8.1.3\n",
            "Best match: click 8.1.3\n",
            "Adding click 8.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for importlib-metadata==5.1.0\n",
            "Best match: importlib-metadata 5.1.0\n",
            "Adding importlib-metadata 5.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numba==0.56.4\n",
            "Best match: numba 0.56.4\n",
            "Adding numba 0.56.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cffi==1.15.1\n",
            "Best match: cffi 1.15.1\n",
            "Adding cffi 1.15.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pandas==1.3.5\n",
            "Best match: pandas 1.3.5\n",
            "Adding pandas 1.3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for multiprocess==0.70.14\n",
            "Best match: multiprocess 0.70.14\n",
            "Adding multiprocess 0.70.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for bce-python-sdk==0.8.74\n",
            "Best match: bce-python-sdk 0.8.74\n",
            "Adding bce-python-sdk 0.8.74 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Flask-Babel==2.0.0\n",
            "Best match: Flask-Babel 2.0.0\n",
            "Adding Flask-Babel 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for humanfriendly==10.0\n",
            "Best match: humanfriendly 10.0\n",
            "Adding humanfriendly 10.0 to easy-install.pth file\n",
            "Installing humanfriendly script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for mpmath==1.2.1\n",
            "Best match: mpmath 1.2.1\n",
            "Adding mpmath 1.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pox==0.3.2\n",
            "Best match: pox 0.3.2\n",
            "Adding pox 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for ppft==1.7.6.6\n",
            "Best match: ppft 1.7.6.6\n",
            "Adding ppft 1.7.6.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for dill==0.3.6\n",
            "Best match: dill 0.3.6\n",
            "Adding dill 0.3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for MarkupSafe==2.1.1\n",
            "Best match: MarkupSafe 2.1.1\n",
            "Adding MarkupSafe 2.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zipp==3.11.0\n",
            "Best match: zipp 3.11.0\n",
            "Adding zipp 3.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for llvmlite==0.39.1\n",
            "Best match: llvmlite 0.39.1\n",
            "Adding llvmlite 0.39.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pycparser==2.21\n",
            "Best match: pycparser 2.21\n",
            "Adding pycparser 2.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for kiwisolver==1.4.4\n",
            "Best match: kiwisolver 1.4.4\n",
            "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pytz==2022.6\n",
            "Best match: pytz 2022.6\n",
            "Adding pytz 2022.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pycryptodome==3.16.0\n",
            "Best match: pycryptodome 3.16.0\n",
            "Adding pycryptodome 3.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Babel==2.11.0\n",
            "Best match: Babel 2.11.0\n",
            "Adding Babel 2.11.0 to easy-install.pth file\n",
            "Installing pybabel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for ppasr==2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1e7t3lOPj0PAgQHWVot0dRw8_NRoP27IN' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1e7t3lOPj0PAgQHWVot0dRw8_NRoP27IN\" -O \"PPASR.zip\" && rm -rf /tmp/cookies.txt\n",
        "!unzip /content/PPASR/PPASR.zip -d /content\n",
        "!cp -RT /content/PPASR_V2-conformer_online-fbank-超大数据集/configs/ /content/PPASR/configs/\n",
        "!cp -RT /content/PPASR_V2-conformer_online-fbank-超大数据集/dataset/ /content/PPASR/dataset/\n",
        "!cp -RT /content/PPASR_V2-conformer_online-fbank-超大数据集/models/ /content/PPASR/models/\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1--Sy7fcquKBR8PNIVW-quDlSD1fCNcGk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1--Sy7fcquKBR8PNIVW-quDlSD1fCNcGk\" -O \"zh_giga.no_cna_cmn.prune01244.klm\" && rm -rf /tmp/cookies.txt\n",
        "!cp -r /content/PPASR/zh_giga.no_cna_cmn.prune01244.klm /content/PPASR/lm/\n",
        "!python export_model.py --resume_model=models/conformer_online_fbank/best_model/"
      ],
      "metadata": {
        "id": "AYkU3kekaQps",
        "outputId": "8ffa8292-6670-4de8-e389-46e7a2d86450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 03:03:47--  https://docs.google.com/uc?export=download&confirm=t&id=1e7t3lOPj0PAgQHWVot0dRw8_NRoP27IN\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.102, 172.217.194.139, 172.217.194.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2qa7k37145k22u985lb6lho5t961vr04/1671591825000/03760087302420967133/*/1e7t3lOPj0PAgQHWVot0dRw8_NRoP27IN?e=download&uuid=21ab9587-88c5-4d52-80ea-17e36d3c5369 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-12-21 03:03:47--  https://doc-14-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2qa7k37145k22u985lb6lho5t961vr04/1671591825000/03760087302420967133/*/1e7t3lOPj0PAgQHWVot0dRw8_NRoP27IN?e=download&uuid=21ab9587-88c5-4d52-80ea-17e36d3c5369\n",
            "Resolving doc-14-8s-docs.googleusercontent.com (doc-14-8s-docs.googleusercontent.com)... 74.125.68.132, 2404:6800:4003:c02::84\n",
            "Connecting to doc-14-8s-docs.googleusercontent.com (doc-14-8s-docs.googleusercontent.com)|74.125.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 455633096 (435M) [application/x-zip-compressed]\n",
            "Saving to: ‘PPASR.zip’\n",
            "\n",
            "PPASR.zip           100%[===================>] 434.53M   181MB/s    in 2.4s    \n",
            "\n",
            "2022-12-21 03:03:50 (181 MB/s) - ‘PPASR.zip’ saved [455633096/455633096]\n",
            "\n",
            "Archive:  /content/PPASR/PPASR.zip\n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/\n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/configs/\n",
            "  inflating: /content/PPASR_V2-conformer_online-fbank-超大数据集/configs/conformer_online_zh.yml  \n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/dataset/\n",
            "  inflating: /content/PPASR_V2-conformer_online-fbank-超大数据集/dataset/mean_istd.json  \n",
            "  inflating: /content/PPASR_V2-conformer_online-fbank-超大数据集/dataset/vocabulary.txt  \n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/models/\n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/models/conformer_online_fbank/\n",
            "   creating: /content/PPASR_V2-conformer_online-fbank-超大数据集/models/conformer_online_fbank/best_model/\n",
            "  inflating: /content/PPASR_V2-conformer_online-fbank-超大数据集/models/conformer_online_fbank/best_model/model.pdparams  \n",
            "--2022-12-21 03:04:01--  https://docs.google.com/uc?export=download&confirm=t&id=1--Sy7fcquKBR8PNIVW-quDlSD1fCNcGk\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.102, 172.217.194.139, 172.217.194.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/neq71jn1orp6oghi1sph5dokfunrjeub/1671591825000/03760087302420967133/*/1--Sy7fcquKBR8PNIVW-quDlSD1fCNcGk?e=download&uuid=94264fcc-cee8-4e03-ae4c-5c5eb443ddf3 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-12-21 03:04:02--  https://doc-00-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/neq71jn1orp6oghi1sph5dokfunrjeub/1671591825000/03760087302420967133/*/1--Sy7fcquKBR8PNIVW-quDlSD1fCNcGk?e=download&uuid=94264fcc-cee8-4e03-ae4c-5c5eb443ddf3\n",
            "Resolving doc-00-8s-docs.googleusercontent.com (doc-00-8s-docs.googleusercontent.com)... 74.125.68.132, 2404:6800:4003:c02::84\n",
            "Connecting to doc-00-8s-docs.googleusercontent.com (doc-00-8s-docs.googleusercontent.com)|74.125.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2953395058 (2.8G) [application/octet-stream]\n",
            "Saving to: ‘zh_giga.no_cna_cmn.prune01244.klm’\n",
            "\n",
            "zh_giga.no_cna_cmn. 100%[===================>]   2.75G   234MB/s    in 12s     \n",
            "\n",
            "2022-12-21 03:04:14 (245 MB/s) - ‘zh_giga.no_cna_cmn.prune01244.klm’ saved [2953395058/2953395058]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/past/translation/__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.8/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.8/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Mapping\n",
            "[\u001b[32m2022-12-21 03:04:33.988477\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m\u001b[37m----------- 额外配置参数 -----------\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988631\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\u001b[37mconfigs: configs/conformer_online_zh.yml\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988704\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\u001b[37mresume_model: models/conformer_online_fbank/best_model/\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988766\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\u001b[37msave_model: models/\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988828\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\u001b[37msave_quant: False\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988894\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\u001b[37muse_gpu: True\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.988958\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1m\u001b[37m------------------------------------------------\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989039\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1m\u001b[37m----------- 配置文件参数 -----------\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989115\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mctc_beam_search_decoder_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989188\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\talpha: 2.2\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989252\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tbeam_size: 300\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989315\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tbeta: 4.3\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989377\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tcutoff_prob: 0.99\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989443\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tcutoff_top_n: 40\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989504\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlanguage_model_path: lm/zh_giga.no_cna_cmn.prune01244.klm\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989565\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnum_processes: 10\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989627\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mdataset_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989692\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tbatch_size: 32\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989751\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tdataset_vocab: dataset/vocabulary.txt\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989812\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tmanifest_type: txt\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989874\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tmax_duration: 20\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.989946\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tmean_istd_path: dataset/mean_istd.json\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990009\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tmin_duration: 0.5\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990079\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnoise_manifest_path: dataset/manifest.noise\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990141\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnum_workers: 4\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990202\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\ttest_manifest: dataset/manifest.test\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990263\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\ttrain_manifest: dataset/manifest.train\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990324\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m\u001b[37mdecoder: ctc_beam_search\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990384\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mdecoder_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990455\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tattention_heads: 8\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990518\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tdropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990578\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlinear_units: 2048\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990640\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnum_blocks: 3\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990717\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tpositional_dropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990788\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tr_num_blocks: 3\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990856\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tself_attention_dropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990925\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tsrc_attention_dropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.990997\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mencoder_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991081\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tactivation_type: swish\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991147\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tattention_dropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991217\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tattention_heads: 8\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991282\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tcnn_module_kernel: 15\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991347\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tdropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991411\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tinput_layer: conv2d\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991479\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlinear_units: 2048\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991544\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnormalize_before: True\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991607\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tnum_blocks: 12\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991671\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\toutput_size: 512\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991734\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tpos_enc_layer_type: rel_pos\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991799\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tpositional_dropout_rate: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991862\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tuse_cnn_module: True\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991927\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m\u001b[37mmetrics_type: cer\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.991991\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mmodel_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992073\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tctc_weight: 0.3\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992144\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlength_normalized_loss: False\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992226\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlsm_weight: 0.1\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992295\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\treverse_weight: 0.3\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992364\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37moptimizer_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992457\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlearning_rate: 0.001\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992529\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\twarmup_steps: 25000\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992600\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tweight_decay: 1e-6\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992671\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mpreprocess_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992744\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tfeature_method: fbank\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992815\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tn_mels: 80\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992886\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tn_mfcc: 40\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.992958\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tsample_rate: 16000\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993062\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\ttarget_dB: -20\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993130\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tuse_dB_normalization: True\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993197\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\u001b[37mtrain_conf:\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993264\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\taccum_grad: 4\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993333\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tgrad_clip: 5.0\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993401\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tlog_interval: 100\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993471\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m\u001b[37m\tmax_epoch: 100\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993541\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m\u001b[37muse_model: conformer_online\u001b[0m\n",
            "[\u001b[32m2022-12-21 03:04:33.993608\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mutils\u001b[0m:\u001b[36mprint_arguments\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m\u001b[37m------------------------------------------------\u001b[0m\n",
            "W1221 03:04:34.012892  1248 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.2\n",
            "W1221 03:04:34.076454  1248 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\n",
            "[\u001b[32m2022-12-21 03:04:42.251575\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mtrainer\u001b[0m:\u001b[36mexport\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1m\u001b[37m成功恢复模型参数和优化方法参数：models/conformer_online_fbank/best_model/model.pdparams\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/jit.py:838: UserWarning: What you save is a function, and `jit.save` will generate the name of the model file according to `path` you specify. When loading these files with `jit.load`, you get a `TranslatedLayer` whose inference result is the same as the inference result of the function you saved.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:211: UserWarning: Return results from different branches in cond are not same type: false_var returned by fasle_fn is '<class 'int'>' and true_var of true_fn is '<class 'paddle.fluid.framework.Variable'>'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:211: UserWarning: Return results from different branches in cond are not same type: false_var returned by fasle_fn is '<class 'paddle.fluid.framework.Variable'>' and true_var of true_fn is '<class 'int'>'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/tensor.py:667: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/paddle/fluid/layers/control_flow.py:124: UserWarning: the input shapes of select_input should have the same rank, but get (1,), (-1, -1, -1, -1)\n",
            "  warnings.warn(\n",
            "[\u001b[32m2022-12-21 03:04:52.292717\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mtrainer\u001b[0m:\u001b[36mexport\u001b[0m:\u001b[36m587\u001b[0m - \u001b[1m\u001b[37m预测模型已保存：models/conformer_online_fbank/infer/model\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lDJIJKRc6a-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02 导入谷歌云盘中的音频压缩文件"
      ],
      "metadata": {
        "id": "I38--T_ic1BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WI6gxEbQDwG",
        "outputId": "4f3e7e7c-5e16-47f0-b28c-9ef2c3163092"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav_file = 'data.zip'#@param {type:\"string\"}\n",
        "wav_path = \"/content/drive/MyDrive/\" + wav_file\n",
        "!unzip $wav_path -d /content/PPASR/raw_wav"
      ],
      "metadata": {
        "id": "1w-FFH64hTPp",
        "outputId": "6749896e-0af6-46ed-d2f5-a09f04783dfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "  inflating: /content/PPASR/raw_wav/lj1216.wav  \n",
            "  inflating: /content/PPASR/raw_wav/aam0511.wav  \n",
            "  inflating: /content/PPASR/raw_wav/alv0805.wav  \n",
            "  inflating: /content/PPASR/raw_wav/hp0317.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LJy5FZKIdERh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03 长音频自动切片为短音频"
      ],
      "metadata": {
        "id": "eREJBxCIdGYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import wave\n",
        "\n",
        "import librosa\n",
        "import soundfile\n",
        "\n",
        "def length(src: str):\n",
        "    if os.path.isfile(src) and src.endswith('.wav'):\n",
        "        with wave.open(src, 'r') as w:\n",
        "            return w.getnframes() / w.getframerate() / 3600\n",
        "    elif os.path.isdir(src):\n",
        "        total = 0\n",
        "        for ch in [os.path.join(src, c) for c in os.listdir(src)]:\n",
        "            total += length(ch)\n",
        "        return total\n",
        "    return 0\n",
        "\n",
        "\n",
        "print('Environment initialized successfully.')\n",
        "\n",
        "# Configuration for data paths\n",
        "raw_path = '/content/PPASR/raw_wav'  # Path to your raw, unsliced recordings\n",
        "\n",
        "########################################\n",
        "\n",
        "assert os.path.exists(raw_path) and os.path.isdir(raw_path), 'The chosen path does not exist or is not a directory.'\n",
        "print('Raw recording path:', raw_path)\n",
        "print()\n",
        "print('===== Recording List =====')\n",
        "raw_filelist = glob.glob(f'{raw_path}/*.wav', recursive=True)\n",
        "raw_length = length(raw_path)\n",
        "if len(raw_filelist) > 5:\n",
        "    print('\\n'.join(raw_filelist[:5] + [f'... ({len(raw_filelist) - 5} more)']))\n",
        "else:\n",
        "    print('\\n'.join(raw_filelist))\n",
        "print()\n",
        "print(f'Found {len(raw_filelist)} valid recordings with total length of {round(raw_length, 2)} hours.')\n",
        "\n",
        "sliced_path = '/content/PPASR/sliced_wav'  # Path to hold the sliced segments of your recordings\n",
        "\n",
        "# Slicer arguments\n",
        "db_threshold_ = -40. #@param {type:\"number\"}\n",
        "min_length_ = 10000 #@param {type:\"number\"}\n",
        "win_l_ = 800 #@param {type:\"number\"}\n",
        "win_s_ = 40 #@param {type:\"number\"}\n",
        "max_silence_kept_ = 1000 #@param {type:\"number\"}\n",
        "\n",
        "# Number of threads (based on your CPU kernels)\n",
        "num_workers = 5\n",
        "\n",
        "########################################\n",
        "\n",
        "assert 'raw_path' in locals().keys(), 'Raw path of your recordings has not been specified.'\n",
        "assert not os.path.exists(sliced_path) or os.path.isdir(sliced_path), 'The chosen path is not a directory.'\n",
        "os.makedirs(sliced_path, exist_ok=True)\n",
        "print('Sliced recording path:', sliced_path)\n",
        "\n",
        "from slicer import Slicer\n",
        "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED\n",
        "\n",
        "def slice_one(in_audio):\n",
        "    audio, sr = librosa.load(in_audio, sr=None)\n",
        "    slicer = Slicer(\n",
        "        sr=sr,\n",
        "        db_threshold=db_threshold_,\n",
        "        min_length=min_length_,\n",
        "        win_l=win_l_,\n",
        "        win_s=win_s_,\n",
        "        max_silence_kept=max_silence_kept_\n",
        "    )\n",
        "    chunks = slicer.slice(audio)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        soundfile.write(os.path.join(sliced_path, f'%s_slice_%04d.wav' % (os.path.basename(in_audio).rsplit('.', maxsplit=1)[0], i)), chunk, sr)\n",
        "\n",
        "\n",
        "print('Slicing your recordings may take several minutes. Please wait.')\n",
        "thread_pool = ThreadPoolExecutor(max_workers=num_workers)\n",
        "tasks = []\n",
        "for file in raw_filelist:\n",
        "    tasks.append(thread_pool.submit(slice_one, file))\n",
        "wait(tasks, return_when=ALL_COMPLETED)\n",
        "print()\n",
        "print('===== Segment List =====')\n",
        "sliced_filelist = glob.glob(f'{sliced_path}/*.wav', recursive=True)\n",
        "sliced_length = length(sliced_path)\n",
        "if len(sliced_filelist) > 5:\n",
        "    print('\\n'.join(sliced_filelist[:5] + [f'... ({len(sliced_filelist) - 5} more)']))\n",
        "else:\n",
        "    print('\\n'.join(sliced_filelist))\n",
        "print()\n",
        "print(f'Sliced your recordings into {len(sliced_filelist)} segments with total length of {round(sliced_length, 2)} hours.')"
      ],
      "metadata": {
        "id": "wS4prYRLgPa5",
        "outputId": "c7334bbe-451f-49ce-dc90-ad91c5200621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment initialized successfully.\n",
            "Raw recording path: /content/PPASR/raw_wav\n",
            "\n",
            "===== Recording List =====\n",
            "/content/PPASR/raw_wav/alv0805.wav\n",
            "/content/PPASR/raw_wav/aam0511.wav\n",
            "/content/PPASR/raw_wav/lj1216.wav\n",
            "/content/PPASR/raw_wav/hp0317.wav\n",
            "\n",
            "Found 4 valid recordings with total length of 0.37 hours.\n",
            "Sliced recording path: /content/PPASR/sliced_wav\n",
            "Slicing your recordings may take several minutes. Please wait.\n",
            "executing 'slice' costed 28.636s\n",
            "executing 'slice' costed 28.903s\n",
            "executing 'slice' costed 36.075s\n",
            "executing 'slice' costed 39.320s\n",
            "\n",
            "===== Segment List =====\n",
            "/content/PPASR/sliced_wav/aam0511_slice_0010.wav\n",
            "/content/PPASR/sliced_wav/hp0317_slice_0005.wav\n",
            "/content/PPASR/sliced_wav/alv0805_slice_0005.wav\n",
            "/content/PPASR/sliced_wav/lj1216_slice_0007.wav\n",
            "/content/PPASR/sliced_wav/alv0805_slice_0015.wav\n",
            "... (75 more)\n",
            "\n",
            "Sliced your recordings into 80 segments with total length of 0.3 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QLLBtmq2dh2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04 切片后的短音频自动转写"
      ],
      "metadata": {
        "id": "pPSPhQtxdizC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd /content/PPASR\n",
        "#ls ./sliced_wav/*.wav\n",
        "for file in ./sliced_wav/*.wav;  #一级目录下的内容-->并不递归显示！ \n",
        "  do  \n",
        "     python infer_path.py --wav_path=$file;  #${file}代表的是文件的全路径\n",
        "  done "
      ],
      "metadata": {
        "id": "UJyiEZEtafYL",
        "outputId": "b3ee4b81-24eb-4fbe-ee40-3fca5440bdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:06:24.904457\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：350ms, 识别结果: 朋友是律师爸爸喜欢看书哥哥是医生\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:06:44.691464\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：403ms, 识别结果: 我喜欢看电视他们是护士高鹏和\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:06:57.837093\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：392ms, 识别结果: 徐涛是邻居他不叫高峰\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:07:10.870216\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：399ms, 识别结果: 弟弟喜欢跳舞打球可是我不喜欢打球\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:07:23.759254\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：320ms, 识别结果: 许涛没有女儿我七点一\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:07:36.469856\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：410ms, 识别结果: 去年女性朋友不是我们是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:07:49.841918\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：532ms, 识别结果: 看得出你这样的又一次吗八月八号是三至五\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:08:02.945670\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：340ms, 识别结果: 高峰和徐涛是邻居我今天\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:08:16.108871\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：490ms, 识别结果: 一改去年律师他们是护士打球可是我不喜欢打球\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:08:29.090790\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：330ms, 识别结果: 我有一个女儿她不叫高朋朋友不是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:08:41.924368\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：378ms, 识别结果: 我们是邻居看书你这样的有意思吗我有一个女儿\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:08:55.194539\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：474ms, 识别结果: 弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书哥哥是一生\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:09:08.205823\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：441ms, 识别结果: 我喜欢看电视八月八号是星期五朋友是律师\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:09:21.549490\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：504ms, 识别结果: 我叫木有房高峰是律师\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:09:35.720672\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：348ms, 识别结果: 高峰住在二十六我我也在二十六住\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:09:48.975796\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：395ms, 识别结果: 我是一个中文的学生我觉得学中文还有一次我每天\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:10:01.906222\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：373ms, 识别结果: 学习中文一书讲这是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:10:14.868694\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：446ms, 识别结果: 一点一点点但是很好今天是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:10:27.793108\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：361ms, 识别结果: 十十九十九九今天是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:10:40.632553\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：340ms, 识别结果: 星期一四四我不知道\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:10:53.938591\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：382ms, 识别结果: 什么说下个时是二十一\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:11:06.911244\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：431ms, 识别结果: 二十一号高峰的女儿喜欢跳舞\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:11:19.794874\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：428ms, 识别结果: 他很喜欢俄罗斯的芭蕾她她很漂亮的\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:11:32.621346\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：311ms, 识别结果: 她是很漂亮的女生哥哥喜欢看书弟弟喜欢\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:11:45.395731\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：314ms, 识别结果: 看电视他看\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:11:58.336681\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：477ms, 识别结果: 哥哥和弟弟在家好玩在北京现在\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:12:13.233467\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：310ms, 识别结果: 十一三十在二十六\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:12:26.215327\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：341ms, 识别结果: 现在五十五十三十二\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:12:38.970748\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：368ms, 识别结果: 北京比我说的是这样的六个小时\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:12:51.997286\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：331ms, 识别结果: 朋友我们去吧喝酒好吗再走吧你可以\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:13:04.922733\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：348ms, 识别结果: 用你的左手和啤酒朋友\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:13:17.752040\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：365ms, 识别结果: 我们可以去打球了我们我们今天去\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:13:30.462285\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：175ms, 识别结果: 去巴拉那州吧好吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:13:43.038640\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：375ms, 识别结果: 朋友是李氏爸爸喜欢看书格格是一生\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:13:55.804876\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：288ms, 识别结果: 我喜欢看电视他们是护士\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:14:08.440974\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：465ms, 识别结果: 高鹏和徐涛是邻居他不叫高峰弟弟喜欢跳舞\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:14:21.255275\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：371ms, 识别结果: 打球可是我不喜欢打球西藏没有女人\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:14:33.898146\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：362ms, 识别结果: 我七点一刻去见李石朋友不是我们是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:14:46.582444\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：311ms, 识别结果: 看书你觉得有意思吗八月八号是星期五\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:15:00.843811\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：485ms, 识别结果: 赵鹏和徐涛是邻居我七点一刻去见李世他们是护士\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:15:13.610650\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：393ms, 识别结果: 打球可是我不喜欢打球我有一个女儿他不再搞\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:15:26.331755\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：506ms, 识别结果: 朋友不是我们是邻居看书你觉得有意思吗我有一个女儿\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:15:39.014741\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：365ms, 识别结果: 弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:15:51.646120\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：388ms, 识别结果: 哥哥是医生我喜欢看电视八月八号是星期五\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:16:04.418437\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：563ms, 识别结果: 朋友是你是他叫高峰\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:16:17.396456\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：394ms, 识别结果: 高峰是李氏在北京朋友的电话号码是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:16:30.106122\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：673ms, 识别结果: 八五八七五八七五今天是\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:16:43.042562\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：389ms, 识别结果: 八月一号今天是星期一今天也是今天是周一\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:16:55.880279\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：616ms, 识别结果: 高鹏的女儿喜欢跳舞她穿白色的衣服哥哥喜欢看书\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:17:08.739316\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：1006ms, 识别结果: 弟弟喜欢看电视哥哥被滴滴滴滴不太聪明北京现在是一点\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:17:22.121273\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：521ms, 识别结果: 二十五现在六点半我们去听音乐会吧好吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:17:35.098914\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：289ms, 识别结果: 我们去乒乓球吧好吗我们去玩乒乓球好\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:17:48.959957\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：365ms, 识别结果: 朋友是律师爸爸喜欢看书哥哥是医生我喜欢看电视\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:18:01.591840\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：308ms, 识别结果: 他们是护士高鹏和许涛是邻居他不叫高鹏\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:18:14.116814\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：345ms, 识别结果: 弟弟喜欢跳舞打球可是我不喜欢打球许涛没有女儿\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:18:26.756602\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：359ms, 识别结果: 我七点一刻去见律师朋友不是我们是邻居看书你觉得有意思吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:18:39.413602\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：331ms, 识别结果: 八月八号是星期五高鹏和许涛是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:18:52.263383\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：336ms, 识别结果: 我七点一刻去见律师他们是护士打球可是我不喜欢打球\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:19:05.044067\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：403ms, 识别结果: 我有一个女儿她不叫高朋朋友不是我们是邻居看书你觉得有意思吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:19:17.698184\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：384ms, 识别结果: 我有一个女儿弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:19:30.269636\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：317ms, 识别结果: 哥哥是医生我喜欢看电视八月八号是星期五\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:19:42.725254\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：970ms, 识别结果: 朋友是律师他叫高峰高峰是律师高鹏在北京工作\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:19:55.958062\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：313ms, 识别结果: 今天是八月一号今天是星期一高鹏的女儿喜欢跳舞\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:20:08.648356\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：502ms, 识别结果: 哥哥喜欢看书弟弟喜欢看电视北京现在是十一点三十分奥斯路现在是五点三十分\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:20:21.519373\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：296ms, 识别结果: 我们去听音乐会吧好吗我们去大乒乓球吧好吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:20:35.377656\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：516ms, 识别结果: 朋友是律师爸爸喜欢看书哥哥是医生我喜欢看电视\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:20:48.292449\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：371ms, 识别结果: 他们是护士高鹏和徐涛是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:21:00.976981\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：339ms, 识别结果: 他不叫高鹏弟弟喜欢跳舞打球可是我不喜欢打球\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:21:13.719345\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：336ms, 识别结果: 徐涛没有女儿我七点一刻去见律师朋友不是我们是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:21:26.438334\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：432ms, 识别结果: 看书你觉得有意思吗八月八号是星期五高鹏和徐涛是邻居\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:21:39.181620\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：486ms, 识别结果: 我七点一刻去见律师他们是护士打球可是我不喜欢打球\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:21:52.081262\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：295ms, 识别结果: 我有一个女儿她不叫高鹏\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:22:04.585675\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：306ms, 识别结果: 朋友不是我们是邻居看书你觉得有意思吗我有一个女儿\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:22:17.072887\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：316ms, 识别结果: 弟弟喜欢跳舞徐涛没有女儿爸爸喜欢看书哥哥是医生\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:22:29.595587\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：364ms, 识别结果: 我喜欢看电视八月八号是星期五朋友是律师他叫高鹏\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:22:42.357084\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：533ms, 识别结果: 高鹏是一名律师高鹏在北京市今天是八月一号\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:22:55.211195\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：432ms, 识别结果: 今天是星期一高鹏的女儿喜欢跳舞哥哥喜欢看书\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:23:07.952541\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：309ms, 识别结果: 弟弟喜欢看电视北京现在十一点半\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:23:21.855340\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：594ms, 识别结果: 奥斯路现在五点半去音乐会吧好吗\n",
            "======================================================================\n",
            "初始化解码器...\n",
            "language model: model path = lm/zh_giga.no_cna_cmn.prune01244.klm, is_character_based = True, max_order = 5, dict_size = 0\n",
            "初始化解码器完成!\n",
            "======================================================================\n",
            "[\u001b[32m2022-12-21 03:23:34.548339\u001b[0m \u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36minference_predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[37m已加载模型：models/conformer_online_fbank/infer/\u001b[0m\n",
            "消耗时间：119ms, 识别结果: 去打乒乓球吧好吗\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pypinyin import pinyin, lazy_pinyin, Style\n",
        "import re\n",
        "\n",
        "root_dir = \"/content/PPASR/sliced_wav\"\n",
        "pattern = re.compile(r'(.*)\\.txt$')\n",
        "r=\"[_.!+-=——,$%^,。?、~@#￥%……&*《》<>「」{}【】()（）/''\\n ]\"\n",
        "\n",
        "for root, dir, files in os.walk(root_dir):\n",
        "\tfor filename in files:\n",
        "\t\t#print(filename)\n",
        "\t\toutput = pattern.match(filename)\n",
        "\t\tif output is not None:\n",
        "\t\t\tprint(root, filename)\n",
        "\t\t\ttext_file = open(root+\"/\"+filename)\n",
        "\t\t\tline = text_file.read().strip()\n",
        "\t\t\tline = line.replace(\"，\", \"\")\n",
        "\t\t\tline = re.sub(r,\"\",line)\n",
        "\t\t\tpinyin =  lazy_pinyin(line, style=Style.TONE3, errors='default', strict=False, v_to_u=False, neutral_tone_with_five=True,tone_sandhi=True)\n",
        "\t\t\tpinyinline = ' '.join(pinyin)\n",
        "\t\t\tprint(line)\n",
        "\t\t\ttarget_text_file = open(root+\"/\"+output.group(1)+\".txt\", \"w\")\n",
        "\t\t\ttarget_text_file.write(pinyinline)\n",
        "\t\t\ttarget_text_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EezcQcTlYu6t",
        "outputId": "68529457-5495-4ea3-b306-3986cf431415"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PPASR/sliced_wav aam0511_slice_0002.txt\n",
            "徐涛是邻居他不叫高峰\n",
            "/content/PPASR/sliced_wav alv0805_slice_0000.txt\n",
            "朋友是李氏爸爸喜欢看书格格是一生\n",
            "/content/PPASR/sliced_wav aam0511_slice_0013.txt\n",
            "我叫木有房高峰是律师\n",
            "/content/PPASR/sliced_wav alv0805_slice_0004.txt\n",
            "我七点一刻去见李石朋友不是我们是邻居\n",
            "/content/PPASR/sliced_wav aam0511_slice_0028.txt\n",
            "北京比我说的是这样的六个小时\n",
            "/content/PPASR/sliced_wav alv0805_slice_0017.txt\n",
            "二十五现在六点半我们去听音乐会吧好吗\n",
            "/content/PPASR/sliced_wav lj1216_slice_0013.txt\n",
            "奥斯路现在五点半去音乐会吧好吗\n",
            "/content/PPASR/sliced_wav hp0317_slice_0004.txt\n",
            "八月八号是星期五高鹏和许涛是邻居\n",
            "/content/PPASR/sliced_wav alv0805_slice_0015.txt\n",
            "高鹏的女儿喜欢跳舞她穿白色的衣服哥哥喜欢看书\n",
            "/content/PPASR/sliced_wav alv0805_slice_0001.txt\n",
            "我喜欢看电视他们是护士\n",
            "/content/PPASR/sliced_wav aam0511_slice_0024.txt\n",
            "看电视他看\n",
            "/content/PPASR/sliced_wav hp0317_slice_0006.txt\n",
            "我有一个女儿她不叫高朋朋友不是我们是邻居看书你觉得有意思吗\n",
            "/content/PPASR/sliced_wav hp0317_slice_0001.txt\n",
            "他们是护士高鹏和许涛是邻居他不叫高鹏\n",
            "/content/PPASR/sliced_wav aam0511_slice_0011.txt\n",
            "弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书哥哥是一生\n",
            "/content/PPASR/sliced_wav lj1216_slice_0000.txt\n",
            "朋友是律师爸爸喜欢看书哥哥是医生我喜欢看电视\n",
            "/content/PPASR/sliced_wav lj1216_slice_0003.txt\n",
            "徐涛没有女儿我七点一刻去见律师朋友不是我们是邻居\n",
            "/content/PPASR/sliced_wav alv0805_slice_0002.txt\n",
            "高鹏和徐涛是邻居他不叫高峰弟弟喜欢跳舞\n",
            "/content/PPASR/sliced_wav aam0511_slice_0008.txt\n",
            "一改去年律师他们是护士打球可是我不喜欢打球\n",
            "/content/PPASR/sliced_wav lj1216_slice_0011.txt\n",
            "今天是星期一高鹏的女儿喜欢跳舞哥哥喜欢看书\n",
            "/content/PPASR/sliced_wav aam0511_slice_0030.txt\n",
            "用你的左手和啤酒朋友\n",
            "/content/PPASR/sliced_wav hp0317_slice_0000.txt\n",
            "朋友是律师爸爸喜欢看书哥哥是医生我喜欢看电视\n",
            "/content/PPASR/sliced_wav hp0317_slice_0010.txt\n",
            "今天是八月一号今天是星期一高鹏的女儿喜欢跳舞\n",
            "/content/PPASR/sliced_wav aam0511_slice_0022.txt\n",
            "他很喜欢俄罗斯的芭蕾她她很漂亮的\n",
            "/content/PPASR/sliced_wav aam0511_slice_0003.txt\n",
            "弟弟喜欢跳舞打球可是我不喜欢打球\n",
            "/content/PPASR/sliced_wav aam0511_slice_0006.txt\n",
            "看得出你这样的又一次吗八月八号是三至五\n",
            "/content/PPASR/sliced_wav lj1216_slice_0001.txt\n",
            "他们是护士高鹏和徐涛是邻居\n",
            "/content/PPASR/sliced_wav aam0511_slice_0032.txt\n",
            "去巴拉那州吧好吗\n",
            "/content/PPASR/sliced_wav alv0805_slice_0016.txt\n",
            "弟弟喜欢看电视哥哥被滴滴滴滴不太聪明北京现在是一点\n",
            "/content/PPASR/sliced_wav aam0511_slice_0005.txt\n",
            "去年女性朋友不是我们是邻居\n",
            "/content/PPASR/sliced_wav aam0511_slice_0014.txt\n",
            "高峰住在二十六我我也在二十六住\n",
            "/content/PPASR/sliced_wav aam0511_slice_0015.txt\n",
            "我是一个中文的学生我觉得学中文还有一次我每天\n",
            "/content/PPASR/sliced_wav aam0511_slice_0017.txt\n",
            "一点一点点但是很好今天是\n",
            "/content/PPASR/sliced_wav aam0511_slice_0029.txt\n",
            "朋友我们去吧喝酒好吗再走吧你可以\n",
            "/content/PPASR/sliced_wav lj1216_slice_0007.txt\n",
            "朋友不是我们是邻居看书你觉得有意思吗我有一个女儿\n",
            "/content/PPASR/sliced_wav hp0317_slice_0005.txt\n",
            "我七点一刻去见律师他们是护士打球可是我不喜欢打球\n",
            "/content/PPASR/sliced_wav lj1216_slice_0008.txt\n",
            "弟弟喜欢跳舞徐涛没有女儿爸爸喜欢看书哥哥是医生\n",
            "/content/PPASR/sliced_wav aam0511_slice_0004.txt\n",
            "许涛没有女儿我七点一\n",
            "/content/PPASR/sliced_wav aam0511_slice_0009.txt\n",
            "我有一个女儿她不叫高朋朋友不是\n",
            "/content/PPASR/sliced_wav aam0511_slice_0031.txt\n",
            "我们可以去打球了我们我们今天去\n",
            "/content/PPASR/sliced_wav aam0511_slice_0023.txt\n",
            "她是很漂亮的女生哥哥喜欢看书弟弟喜欢\n",
            "/content/PPASR/sliced_wav hp0317_slice_0007.txt\n",
            "我有一个女儿弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书\n",
            "/content/PPASR/sliced_wav hp0317_slice_0008.txt\n",
            "哥哥是医生我喜欢看电视八月八号是星期五\n",
            "/content/PPASR/sliced_wav lj1216_slice_0004.txt\n",
            "看书你觉得有意思吗八月八号是星期五高鹏和徐涛是邻居\n",
            "/content/PPASR/sliced_wav lj1216_slice_0006.txt\n",
            "我有一个女儿她不叫高鹏\n",
            "/content/PPASR/sliced_wav hp0317_slice_0012.txt\n",
            "我们去听音乐会吧好吗我们去大乒乓球吧好吗\n",
            "/content/PPASR/sliced_wav aam0511_slice_0018.txt\n",
            "十十九十九九今天是\n",
            "/content/PPASR/sliced_wav hp0317_slice_0011.txt\n",
            "哥哥喜欢看书弟弟喜欢看电视北京现在是十一点三十分奥斯路现在是五点三十分\n",
            "/content/PPASR/sliced_wav hp0317_slice_0002.txt\n",
            "弟弟喜欢跳舞打球可是我不喜欢打球许涛没有女儿\n",
            "/content/PPASR/sliced_wav lj1216_slice_0009.txt\n",
            "我喜欢看电视八月八号是星期五朋友是律师他叫高鹏\n",
            "/content/PPASR/sliced_wav aam0511_slice_0007.txt\n",
            "高峰和徐涛是邻居我今天\n",
            "/content/PPASR/sliced_wav aam0511_slice_0026.txt\n",
            "十一三十在二十六\n",
            "/content/PPASR/sliced_wav alv0805_slice_0007.txt\n",
            "打球可是我不喜欢打球我有一个女儿他不再搞\n",
            "/content/PPASR/sliced_wav alv0805_slice_0011.txt\n",
            "朋友是你是他叫高峰\n",
            "/content/PPASR/sliced_wav alv0805_slice_0003.txt\n",
            "打球可是我不喜欢打球西藏没有女人\n",
            "/content/PPASR/sliced_wav lj1216_slice_0005.txt\n",
            "我七点一刻去见律师他们是护士打球可是我不喜欢打球\n",
            "/content/PPASR/sliced_wav lj1216_slice_0010.txt\n",
            "高鹏是一名律师高鹏在北京市今天是八月一号\n",
            "/content/PPASR/sliced_wav aam0511_slice_0027.txt\n",
            "现在五十五十三十二\n",
            "/content/PPASR/sliced_wav aam0511_slice_0016.txt\n",
            "学习中文一书讲这是\n",
            "/content/PPASR/sliced_wav alv0805_slice_0014.txt\n",
            "八月一号今天是星期一今天也是今天是周一\n",
            "/content/PPASR/sliced_wav aam0511_slice_0021.txt\n",
            "二十一号高峰的女儿喜欢跳舞\n",
            "/content/PPASR/sliced_wav alv0805_slice_0009.txt\n",
            "弟弟喜欢跳舞许涛没有女儿爸爸喜欢看书\n",
            "/content/PPASR/sliced_wav aam0511_slice_0012.txt\n",
            "我喜欢看电视八月八号是星期五朋友是律师\n",
            "/content/PPASR/sliced_wav alv0805_slice_0018.txt\n",
            "我们去乒乓球吧好吗我们去玩乒乓球好\n",
            "/content/PPASR/sliced_wav lj1216_slice_0012.txt\n",
            "弟弟喜欢看电视北京现在十一点半\n",
            "/content/PPASR/sliced_wav alv0805_slice_0010.txt\n",
            "哥哥是医生我喜欢看电视八月八号是星期五\n",
            "/content/PPASR/sliced_wav alv0805_slice_0005.txt\n",
            "看书你觉得有意思吗八月八号是星期五\n",
            "/content/PPASR/sliced_wav alv0805_slice_0008.txt\n",
            "朋友不是我们是邻居看书你觉得有意思吗我有一个女儿\n",
            "/content/PPASR/sliced_wav aam0511_slice_0025.txt\n",
            "哥哥和弟弟在家好玩在北京现在\n",
            "/content/PPASR/sliced_wav aam0511_slice_0010.txt\n",
            "我们是邻居看书你这样的有意思吗我有一个女儿\n",
            "/content/PPASR/sliced_wav aam0511_slice_0020.txt\n",
            "什么说下个时是二十一\n",
            "/content/PPASR/sliced_wav alv0805_slice_0006.txt\n",
            "赵鹏和徐涛是邻居我七点一刻去见李世他们是护士\n",
            "/content/PPASR/sliced_wav alv0805_slice_0012.txt\n",
            "高峰是李氏在北京朋友的电话号码是\n",
            "/content/PPASR/sliced_wav aam0511_slice_0000.txt\n",
            "朋友是律师爸爸喜欢看书哥哥是医生\n",
            "/content/PPASR/sliced_wav aam0511_slice_0019.txt\n",
            "星期一四四我不知道\n",
            "/content/PPASR/sliced_wav hp0317_slice_0009.txt\n",
            "朋友是律师他叫高峰高峰是律师高鹏在北京工作\n",
            "/content/PPASR/sliced_wav aam0511_slice_0001.txt\n",
            "我喜欢看电视他们是护士高鹏和\n",
            "/content/PPASR/sliced_wav lj1216_slice_0002.txt\n",
            "他不叫高鹏弟弟喜欢跳舞打球可是我不喜欢打球\n",
            "/content/PPASR/sliced_wav alv0805_slice_0013.txt\n",
            "八五八七五八七五今天是\n",
            "/content/PPASR/sliced_wav lj1216_slice_0014.txt\n",
            "去打乒乓球吧好吗\n",
            "/content/PPASR/sliced_wav hp0317_slice_0003.txt\n",
            "我七点一刻去见律师朋友不是我们是邻居看书你觉得有意思吗\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import Audio\n",
        "#wn = Audio('/content/PPASR/sliced_wav/aam0511_slice_0006.wav', autoplay=True)\n",
        "#with open('/content/PPASR/sliced_wav/aam0511_slice_0006.txt', 'r') as f:\n",
        "    #print(f.read())\n",
        "#display(wn)"
      ],
      "metadata": {
        "id": "bxLEdww1ZzEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 05 保存短音频和对应转写到谷歌云盘"
      ],
      "metadata": {
        "id": "F4AMQtOAeBrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, tarfile\n",
        "import os\n",
        "from google.colab import files\n",
        "save_as = 'mfa_prepare.tar'#@param {type:\"string\"}\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "  tar = tarfile.open(output_filename,\"w\")\n",
        "  for root,dir_name,files_list in os.walk(source_dir):\n",
        "    for file in files_list:\n",
        "      pathfile = os.path.join(root, file)\n",
        "      tar.add(pathfile)\n",
        "  tar.close()\n",
        " \n",
        "  # files.download(output_filename)\n",
        "\n",
        "make_targz_one_by_one(save_as, '/content/PPASR/sliced_wav')\n",
        "savename = \"/content/PPASR/\" + save_as\n",
        "!cp -r $savename /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "JQeP-Gf1au1C"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "欢迎使用 Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}