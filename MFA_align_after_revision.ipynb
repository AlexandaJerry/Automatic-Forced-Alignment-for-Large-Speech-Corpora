{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 从网盘导入数据"
      ],
      "metadata": {
        "id": "SmVfcagojla_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlexandaJerry/PPASR.git\n",
        "%cd /content/PPASR"
      ],
      "metadata": {
        "id": "XmeqbX201OeN",
        "outputId": "4a25437b-0d14-4c53-83f9-37e94fce774b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PPASR'...\n",
            "remote: Enumerating objects: 2275, done.\u001b[K\n",
            "remote: Counting objects: 100% (473/473), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 2275 (delta 338), reused 417 (delta 309), pack-reused 1802\u001b[K\n",
            "Receiving objects: 100% (2275/2275), 32.09 MiB | 28.75 MiB/s, done.\n",
            "Resolving deltas: 100% (1629/1629), done.\n",
            "/content/PPASR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav_dir = 'inputs'#@param {type:\"string\"}\n",
        "wav_path = '/content/PPASR/' + wav_dir\n",
        "textgrid_dir = 'outputs'#@param {type:\"string\"}\n",
        "textgrid_path = '/content/PPASR/' + textgrid_dir\n",
        "acoustic_model = '/content/PPASR/mandarin.zip'\n",
        "dictionary = '/content/PPASR/mandarin_pinyin.txt'\n",
        "%mkdir $wav_dir\n",
        "%mkdir $textgrid_dir"
      ],
      "metadata": {
        "id": "GCrQ3U3U1QoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3kBKrihT2C9v",
        "outputId": "490b1366-5017-4179-b8da-a4f30fdcd348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'data.zip'#@param {type:\"string\"}\n",
        "file_path = \"/content/drive/MyDrive/\" + file_name\n",
        "!unzip -j $file_path \"*.wav\" -d $wav_path\n",
        "!unzip -j $file_path \"*.txt\" -d $wav_path"
      ],
      "metadata": {
        "id": "Mt2RFeTH2GCw",
        "outputId": "3f097f03-bc5b-4895-99df-c52111c39bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0000.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0001.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0002.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0003.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0004.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0005.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0006.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0007.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0008.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0009.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0010.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0011.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0012.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0013.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0014.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0015.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0016.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0017.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0018.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0019.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0020.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0021.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0022.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0023.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0024.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0025.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0026.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0027.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0028.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0029.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0030.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0031.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0032.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0033.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0034.wav  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0035.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0000.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0001.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0002.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0003.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0004.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0005.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0006.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0007.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0008.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0009.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0010.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0011.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0012.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0013.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0014.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0015.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0016.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0017.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0018.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0019.wav  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0020.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0000.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0001.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0002.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0003.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0004.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0005.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0006.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0007.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0008.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0009.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0010.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0011.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0012.wav  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0013.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0000.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0001.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0002.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0003.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0004.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0005.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0006.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0007.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0008.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0009.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0010.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0011.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0012.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0013.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0014.wav  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0015.wav  \n",
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0000.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0001.txt  \n",
            " extracting: /content/PPASR/inputs/aam0511_slice_0002.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0003.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0004.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0005.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0006.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0007.txt  \n",
            " extracting: /content/PPASR/inputs/aam0511_slice_0008.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0009.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0010.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0011.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0012.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0013.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0014.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0015.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0016.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0017.txt  \n",
            " extracting: /content/PPASR/inputs/aam0511_slice_0018.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0019.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0020.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0021.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0022.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0023.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0024.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0025.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0026.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0027.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0028.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0029.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0030.txt  \n",
            " extracting: /content/PPASR/inputs/aam0511_slice_0031.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0032.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0033.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0034.txt  \n",
            "  inflating: /content/PPASR/inputs/aam0511_slice_0035.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0000.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0001.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0002.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0003.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0004.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0005.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0006.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0007.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0008.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0009.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0010.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0011.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0012.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0013.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0014.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0015.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0016.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0017.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0018.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0019.txt  \n",
            "  inflating: /content/PPASR/inputs/alv0805_slice_0020.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0000.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0001.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0002.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0003.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0004.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0005.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0006.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0007.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0008.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0009.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0010.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0011.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0012.txt  \n",
            "  inflating: /content/PPASR/inputs/hp0317_slice_0013.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0000.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0001.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0002.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0003.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0004.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0005.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0006.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0007.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0008.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0009.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0010.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0011.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0012.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0013.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0014.txt  \n",
            "  inflating: /content/PPASR/inputs/lj1216_slice_0015.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 安装MFA\n",
        "#### 安装无误会显示2.0.6"
      ],
      "metadata": {
        "id": "X-Qa5GKkkAHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_miniconda()\n",
        "!conda env create -n aligner -f environment.yml"
      ],
      "metadata": {
        "id": "KpHVa0wi6Ysx",
        "outputId": "c58b3551-04af-49eb-c10d-055152b2b2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:21\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate aligner; \\\n",
        "mfa version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgy8sSS-j-AY",
        "outputId": "07d3566e-fd85-4f7c-a1ed-86d77be0f41c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /usr/local/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "/usr/local/envs/aligner/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
            "  warnings.warn(\n",
            "2.0.6\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 对齐前检测有无超出词典范围的词出现"
      ],
      "metadata": {
        "id": "qCy_SBjfwKpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 加载MFA普通话词典检测有无超出词典范围的词出现\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import wave\n",
        "\n",
        "import librosa\n",
        "import soundfile\n",
        "import tqdm\n",
        "\n",
        "wav_dir = 'inputs'\n",
        "sliced_path = '/content/PPASR/' + wav_dir\n",
        "dict_path = '/content/PPASR/mandarin_pinyin.txt'\n",
        "with open(dict_path, 'r', encoding='utf8') as f:\n",
        "    rules = [ln.strip().split('\\t') for ln in f.readlines()]\n",
        "dictionary = {}\n",
        "phoneme_set = set()\n",
        "for r in rules:\n",
        "    phonemes = r[1].split()\n",
        "    dictionary[r[0]] = phonemes\n",
        "    phoneme_set.update(phonemes)\n",
        "\n",
        "# Run checks\n",
        "check_failed = False\n",
        "covered = set()\n",
        "phoneme_map = {}\n",
        "for ph in sorted(phoneme_set):\n",
        "    phoneme_map[ph] = 0\n",
        "\n",
        "segment_pairs = []\n",
        "sliced_filelist = glob.glob(f'{sliced_path}/*.wav', recursive=True)\n",
        "for file in tqdm.tqdm(sliced_filelist):\n",
        "    filename = os.path.basename(file)\n",
        "    name_without_ext = filename.rsplit('.', maxsplit=1)[0]\n",
        "    annotation = os.path.join(sliced_path, f'{name_without_ext}.txt')\n",
        "    if not os.path.exists(annotation):\n",
        "        print(f'No annotation found for \\'{filename}\\'!')\n",
        "        check_failed = True\n",
        "    with open(annotation, 'r', encoding='utf8') as f:\n",
        "        syllables = f.read().strip().split()\n",
        "    if not syllables:\n",
        "        print(f'Annotation file \\'{annotation}\\' is empty!')\n",
        "        check_failed = True\n",
        "    else:\n",
        "        oov = []\n",
        "        for s in syllables:\n",
        "            if s not in dictionary:\n",
        "                oov.append(s)\n",
        "            else:\n",
        "                for ph in dictionary[s]:\n",
        "                    phoneme_map[ph] += 1\n",
        "                covered.update(dictionary[s])\n",
        "        if oov:\n",
        "            print(f'Syllable(s) {oov} not allowed in annotation file \\'{annotation}\\'')\n",
        "            check_failed = True\n",
        "\n",
        "        else:\n",
        "          print('no out-of-vocabulary words found in annotation files')"
      ],
      "metadata": {
        "id": "oyQ_fRIfsceL",
        "outputId": "6f6a2973-5edc-4686-ca80-c261d3fde2dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 87/87 [00:00<00:00, 1977.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n",
            "no out-of-vocabulary words found in annotation files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r_2NeWQ2rYYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 短音频对齐示范\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### mfa align命令必须输入的参数包括四个路径：\n",
        "#### 01音频和转写的路径 02词典的路径 03声学模型的路径 04输出textgrid的路径\n",
        "#### 我们的词典是拼音词典mandarin_pinyin.txt\n",
        "#### 我们的声学模型路径是mandarin.zip\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### mfa align命令可以自由选择输入的参数包括：\n",
        "#### --clean → 清除上次对齐时保留的缓存文件\n",
        "#### -s number → 文件名中的前多少个字母为发音人的ID\n",
        "#### 例如前两位文件名是发音人的ID，我们会用-s 2进行发音人的区分\n",
        "#### --beam number → 对齐搜索的精度默认数字为10\n",
        "#### 正常情况不需要修改beam，如果无法对齐则需要增大beam\n",
        "#### --overwrite → 覆盖上次对齐好的Textgrid\n",
        "\n",
        "---\n",
        "\n",
        "### 示范命令：\n",
        "!mfa align --clean -s 2 wav_txt_dir dictionary_path acoustic_model_dir textgrids_dir --beam 10 --overwrite\n"
      ],
      "metadata": {
        "id": "Y8R5xDgqk2n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicer arguments\n",
        "speaker_id = 6 #@param {type:\"number\"}\n",
        "beam_number = 100 #@param {type:\"number\"}\n",
        "wav_dir = 'inputs'\n",
        "wav_path = '/content/PPASR/' + wav_dir\n",
        "textgrid_dir = 'outputs'\n",
        "textgrid_path = '/content/PPASR/' + textgrid_dir\n",
        "acoustic_model = '/content/PPASR/mandarin.zip'\n",
        "dictionary = '/content/PPASR/mandarin_pinyin.txt'\n",
        "\n",
        "!source activate aligner; \\\n",
        "mfa align --clean -s $speaker_id $wav_path $dictionary $acoustic_model $textgrid_path --beam $beam_number --overwrite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emuS0W596NO0",
        "outputId": "e0ed6573-7b7c-4140-e84b-bac72e1974db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/aligner/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
            "  warnings.warn(\n",
            "\u001b[32mINFO\u001b[0m - Setting up corpus information...\n",
            "\u001b[32mINFO\u001b[0m - Loading corpus from source files...\n",
            "100% 87/87 [00:01<00:00, 81.81it/s]\n",
            "\u001b[32mINFO\u001b[0m - Found 4 speakers across 87 files, average number of utterances per speaker: 21.75\n",
            "\u001b[32mINFO\u001b[0m - Initializing multiprocessing jobs...\n",
            "\u001b[32mINFO\u001b[0m - Creating corpus split for feature generation...\n",
            "\u001b[32mINFO\u001b[0m - Generating base features (mfcc)...\n",
            "\u001b[32mINFO\u001b[0m - Generating MFCCs...\n",
            " 92% 80/87 [00:06<00:00, 13.26it/s]\n",
            "\u001b[32mINFO\u001b[0m - Calculating CMVN...\n",
            "\u001b[32mINFO\u001b[0m - Creating corpus split with features...\n",
            "\u001b[32mINFO\u001b[0m - Compiling training graphs...\n",
            "100% 87/87 [00:01<00:00, 62.91it/s] \n",
            "\u001b[32mINFO\u001b[0m - Performing first-pass alignment...\n",
            "\u001b[32mINFO\u001b[0m - Generating alignments...\n",
            "100% 87/87 [00:30<00:00,  2.87it/s]\n",
            "\u001b[32mINFO\u001b[0m - Calculating fMLLR for speaker adaptation...\n",
            "100% 4/4 [00:02<00:00,  1.41it/s]\n",
            "\u001b[32mINFO\u001b[0m - Performing second-pass alignment...\n",
            "\u001b[32mINFO\u001b[0m - Generating alignments...\n",
            "100% 87/87 [00:18<00:00,  4.79it/s]\n",
            "\u001b[32mINFO\u001b[0m - Exporting TextGrids to /content/PPASR/outputs...\n",
            "\u001b[32mINFO\u001b[0m - Collecting phone and word alignments from alignment lattices...\n",
            "100% 87/87 [00:01<00:00, 44.88it/s]\n",
            "100% 87/87 [00:02<00:00, 42.59it/s]\n",
            "\u001b[32mINFO\u001b[0m - Finished exporting TextGrids to /content/PPASR/outputs!\n",
            "\u001b[32mINFO\u001b[0m - Done! Everything took 68.96553158760071 seconds\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "zip_name_you_wish = 'textgrid.zip'#@param {type:\"string\"}\n",
        "zip_path = '/content/PPASR/' + zip_name_you_wish\n",
        "!zip -j $zip_path $textgrid_path/*\n",
        "!cp -i $zip_path \"/content/drive/MyDrive/\"\n",
        "print(\"files have been saved to MyDrive\")\n",
        "print(\"files would be automatically downloaded after several seconds\")\n",
        "files.download(zip_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cgU5FZFFpa4B",
        "outputId": "0865f014-f5bd-4cbc-87a8-6105c35e94b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: aam0511_slice_0000.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0001.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0002.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0003.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0004.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0005.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0006.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0007.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0008.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0009.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0010.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0011.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0012.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0013.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0014.TextGrid (deflated 85%)\n",
            "  adding: aam0511_slice_0015.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0016.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0017.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0018.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0019.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0020.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0021.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0022.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0023.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0024.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0025.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0026.TextGrid (deflated 84%)\n",
            "  adding: aam0511_slice_0027.TextGrid (deflated 88%)\n",
            "  adding: aam0511_slice_0028.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0029.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0030.TextGrid (deflated 86%)\n",
            "  adding: aam0511_slice_0031.TextGrid (deflated 85%)\n",
            "  adding: aam0511_slice_0032.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0033.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0034.TextGrid (deflated 87%)\n",
            "  adding: aam0511_slice_0035.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0000.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0001.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0002.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0003.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0004.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0005.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0006.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0007.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0008.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0009.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0010.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0011.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0012.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0013.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0014.TextGrid (deflated 87%)\n",
            "  adding: alv0805_slice_0015.TextGrid (deflated 89%)\n",
            "  adding: alv0805_slice_0016.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0017.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0018.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0019.TextGrid (deflated 88%)\n",
            "  adding: alv0805_slice_0020.TextGrid (deflated 86%)\n",
            "  adding: hp0317_slice_0000.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0001.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0002.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0003.TextGrid (deflated 87%)\n",
            "  adding: hp0317_slice_0004.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0005.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0006.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0007.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0008.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0009.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0010.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0011.TextGrid (deflated 88%)\n",
            "  adding: hp0317_slice_0012.TextGrid (deflated 89%)\n",
            "  adding: hp0317_slice_0013.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0000.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0001.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0002.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0003.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0004.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0005.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0006.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0007.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0008.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0009.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0010.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0011.TextGrid (deflated 86%)\n",
            "  adding: lj1216_slice_0012.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0013.TextGrid (deflated 88%)\n",
            "  adding: lj1216_slice_0014.TextGrid (deflated 87%)\n",
            "  adding: lj1216_slice_0015.TextGrid (deflated 85%)\n",
            "cp: overwrite '/content/drive/MyDrive/textgrid.zip'? y\n",
            "files has been saved to MyDrive\n",
            "files would be automatically downloaded after several seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8cb1093b-fd69-46ee-9586-89aa6746ebc0\", \"textgrid.zip\", 85892)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}